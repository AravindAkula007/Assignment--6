# Import necessary libraries
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

# Load the dataset
data = pd.read_csv("G:\ExcelR\Data Science Assignments\Assignment 6\MLR\\ToyotaCorolla - MLR.csv")
df.head() # Display the first few rows of the dataset

# Summary statistics
print(data.describe())

# Visualizations
# Distribution plots
sns.pairplot(data)
plt.show()

# Correlation heatmap
correlation_matrix = data.corr()
sns.heatmap(correlation_matrix, annot=True, cmap="YlGnBu")
plt.show()

# 2 - Preprocess the data for MLR
# - Create dummy variables for categorical variables
df_dummies = pd.get_dummies(df, drop_first=True)
# - Scale numerical variables
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
df_scaled = scaler.fit_transform(df_dummies)
print(df_scaled,df_dummies)

from sklearn.model_selection import train_test_split

# Define features and target variable
X = data.drop(columns=['Price'])
y = data['Age_08_04']

# Split the dataset into training and testing sets (80% training, 20% testing)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

from sklearn.linear_model import LinearRegression
# Import LabelEncoder for encoding categorical variables
from sklearn.preprocessing import LabelEncoder

# Create a LabelEncoder object
label_encoder = LabelEncoder()

# Encode the 'FuelType' column
data['Fuel_Type_Diesel'] = label_encoder.fit_transform(data['Fuel_Type_Diesel'])

# Drop the 'Price' column temporarily
X = data.drop(columns=['Price'])

# Split the dataset into training and testing sets (80% training, 20% testing)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize the model
model = LinearRegression()

# Fit the model on training data
model.fit(X_train, y_train)

# Coefficients
coefficients = pd.DataFrame({'Variable': X.columns, 'Coefficient': model.coef_})
print(coefficients)

# Predictions on the test set
y_pred = model.predict(X_test)

from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# Evaluation metrics
print('Mean Absolute Error:', mean_absolute_error(y_test, y_pred))
print('Mean Squared Error:', mean_squared_error(y_test, y_pred))
print('R-squared:', r2_score(y_test, y_pred))

#Applying Lasso Methods with both Training and Test Errors

from sklearn.linear_model import Lasso
#LS = Lasso(alpha=1)-->Training Error 0.06,Test Error 0.06
#LS = Lasso(alpha=3)-->Training Error 0.19,Test Error 0.18
#LS = Lasso(alpha=4)-->Training Error 0.25,Test Error 0.24
#LS = Lasso(alpha=5)-->Training Error 0.32,Test Error 0.30
LS = Lasso(alpha=7)#-->Training Error 0.45,Test Error 0.42

LS.fit(X_train,y_train)
Y_pred_train = LS.predict(X_train)
Y_pred_test = LS.predict(X_test)

#MSE 
from sklearn.metrics import mean_squared_error
mse1 = mean_squared_error(y_train,Y_pred_train)
mse2 = mean_squared_error(y_test,Y_pred_test)

#RMSE
import numpy as np
training_error = np.sqrt(mse1)
test_error = np.sqrt(mse2)
print("Lasso Regression: Training Error", training_error.round(2))
print("Lasso Regression: Test Error", test_error.round(2))


# Finding Ridge & Lasso from Regularization
from sklearn.linear_model import Ridge
RR = Ridge(alpha = 1000) #setting the alpha values randomly

RR.fit(X_train,y_train) #fitting the model
y_pred_train = RR.predict(X_train)
y_pred_test = RR.predict(X_test)

#MSE
from sklearn.metrics import mean_squared_error
mse1 = mean_squared_error(y_train,Y_pred_train)
mse2 = mean_squared_error(y_test,Y_pred_test)

#RMSE
import numpy as np
training_error = np.sqrt(mse1)
test_error = np.sqrt(mse2)
print("Ridge Regression: Training Error", training_error.round(2))
print("Ridge Regression: Test Error", test_error.round(2))
